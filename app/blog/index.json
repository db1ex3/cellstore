{ "title" : "28.io - Query Platform for MongoDB", "tags" : { "secxbrl" : 0, "xbrl" : 0, "tutorial" : 0, "jsoniq" : 0, "events" : 0, "white-paper" : 0, "use-case" : 0, "webinar" : 0, "mongodb" : 0 }, "entries" : [ { "title" : "Launch of SECXBRL.info, powered by 28.io", "id" : "/81678006917/launch-of-secxbrlinfo-powered-by-28io", "updated" : "Fri, 04 Apr 2014 09:48:00 -0400", "summary" : "We are excited to announce a new way you to explore financial and business information: secxbrl.info.", "content" : "<blockquote>\n<p>The SEC XBRL financial filing guessing game is over! You can do this for any concept, any axis. Point&#8230; click&#8230; ship.</p>\n<p>- Charles Hoffman</p>\n</blockquote>\n<p>We are excited to announce a new way you to explore financial and business information: <a href=\"http://secxbrl.info\" title=\"US Public Company Financial Information Repository\" target=\"_blank\">secxbrl.info</a>.</p>\n<p>The financial crisis of 2008 made it clear to everybody what happens if important financial information is not readily accessible in an accurate, timely, easy-to-use, and affordable manner. On January 30, 2009, the SEC issued rules mandating public companies to provide their financial statement information using the eXtensible Business Reporting Language (âXBRLâ) interactive data format. Yet, even four years later, in December 2012, Suzanne Morsfield and Trevor Harris had to state in a widely-read report that &#8220;without a serious reconsideration of the technology, coupled with a focus on facile usability of the data, and value-add consumption tools, it will at best remain of marginal benefit to the target audience of both its early proponents and the SECâs mandateâinvestors and analysts.&#8221;</p>\n<p>In March 2014, <a href=\"http://28msec.com\" target=\"_blank\">28msec</a> launched <a href=\"http://secxbrl.info\" title=\"US Public Company Financial Information Repository\" target=\"_blank\">secxbrl.info</a>, a technological breakthrough that is delivering XBRL&#8217;s promise. Or as Charles Hoffman, co-inventor of XBRL, puts it: âThe SEC XBRL financial filing guessing game is over!â Designed as a service to provide access to financial information the way it should be, <a href=\"http://secxbrl.info\" title=\"US Public Company Financial Information Repository\" target=\"_blank\">secxbrl.info</a> enables flexible, ad-hoc, and real-time analysis of all yearly (10-K) and quarterly (10-Q) financial reports of US public companies that have been submitted to the SEC since 2010.</p>\n<p><a href=\"http://secxbrl.info\" title=\"US Public Company Financial Information Repository\" target=\"_blank\">secxbrl.info</a> is powered by the game-changing <a href=\"http://28.io\" target=\"_blank\">28.io</a> information processing platform. This allows for virtually limitless customization and even for turning it into your own private business reporting solution tailored to your specific analytical needs and using your own XBRL-based information.</p>", "tags" : [ "secxbrl", "xbrl" ] }, { "title" : "Web Scraping with JSONiq", "id" : "/81481636286/web-scraping-with-jsoniq", "updated" : "Wed, 02 Apr 2014 08:26:00 -0400", "summary" : "Using the JSONiq query language, you can easily extract data from web pages. As an example we created a “web scraper” that allows you to convert HTML table data to CSV format.", "content" : "<p>Structured data is often published as part of websites using HTML tables. However, data embedded inside HTML can often be challenging to process as structured data. Using the JSONiq query language, you can easily extract data from web pages. As an example we created a &#8220;web scraper&#8221; that allows you to convert HTML table data to CSV format. You can try it out right now at <a href=\"http://html-table-to-csv.28.io/form.jq\">http://html-table-to-csv.28.io/form.jq</a> (Git Repository: <a href=\"https://github.com/28msec/html-table-to-csv\">https://github.com/28msec/html-table-to-csv</a>). The queries are powered by the 28.io platform.</p>\n<p><a href=\"http://html-table-to-csv.28.io/form.jq\"><img alt=\"\" height=\"318\" src=\"https://28msec.zendesk.com/hc/en-us/article_attachments/200608008/Screenshot_2014-04-02_14.21.28.png\" width=\"370\"/></a></p>\n<p>Extracting data from HTML tables of external sources may be challenging as table cells may be merged using the HTML attributes colspan or rowspan making it hard to identify which data belongs together column-wise. The HTML page may be littered with tables misused for doing the layout so that the target table is hard to select.</p>\n<p>The web scraper has several options and built-in features to handle difficult pages: As a minimum, the URL of the page containing the data table must be passed as parameter. First the page is fetched from the given URL using an HTTP get and the HTML or XHTML content is parsed. Using JSONiq, only two lines of code are required for these steps.</p>\n<pre>variable $result := http:get($url);\nvariable $parsed := h:parse($result.body.content);</pre>\n<p>Next, the table containing the data must be identified. Per default, this is done by searching for the table having the most cells that does not have a nested table. By using optional parameters, the table may be selected by its ID attribute, CSS classname or number of occurrences. Using XPath expressions, it is easy to find interesting elements in the parsed page.</p>\n<pre>(: Select table by #id :)\n(\n    $parsed/descendant::element()[@id eq $table-id]/descendant-or-self::*:table,\n    $parsed/descendant::element()[@id eq $table-id]/following::*:table\n)[1]\n\n(: Select table by .classname :)\n$parsed/descendant::element()[tokenize(@class, \" \") = $table-class]/descendant-or-self::*:table,\n$parsed/descendant::element()[tokenize(@class, \" \") = $table-class]/following::*:table\n\n(: Select largest table :)\n(\n    for $candidate in $parsed/descendant::*:table\n    where not($candidate/descendant::*:table)\n    let $amount-of-data := count($candidate/descendant::*:td)\n    order by $amount-of-data descending\n    return $candidate\n)[1]\n</pre>\n<p>After the table is identified, the area containing the data to be extracted and the area containing the column headers are determined. The HTML tables may have been created using elements as the standard suggests or not. Elements may be used for the headings as recommended elements like for the other cells. The web scraper transforms the table into a sequence of rows so that these variances in format no longer make a difference. Also, two parameters allow to skip or truncate rows at the beginning or end of the table.</p>\n<p>In order to get rid of colspan and rowspan attributes the web scraper duplicates these cells multiple times inside a row (colspan) or across multiple rows (rowspan).</p>\n<pre>(: Repeat cells with rowspan accross rows :)\nvariable $table-rows := \n  for $row in $table-rows-with-rowspan-no-colspan\n  return\n      &lt;tr&gt;\n          {      \n              variable $read-column-index := 0;\n              $current-rowspans :=\n                for $col in $current-rowspans\n                return\n                    if ($col.rowspan gt 1)\n                    then { rowspan : $col.rowspan - 1 }\n                    else {\n                        $read-column-index := $read-column-index + 1;\n                        { \n                            rowspan : (integer($row/element()[$read-column-index]/@rowspan), 1)[1], \n                            index : $read-column-index \n                        }\n                    };\n              for $col in $current-rowspans      \n              return \n                  if (exists($col.index)) \n                  then $row/element()[$col.index] \n                  else &lt;td&gt;&lt;/td&gt;\n          } \n       &lt;/tr&gt;;</pre>\n<p>To generate the output, the data cells a FLOWR query is used to iterate over all rows. A JSON object having the column titles as key and the data as values is created for each row.</p>\n<p>The sequence of JSON objects can then be serialized to CSV in one line of code using <a href=\"http://www.28.io/blog/78740141630/converting-between-json--csv\">the json-csv module that we presented in an earlier blog post</a>.</p>\n<pre>csv:serialize($actual-data, { field-names : [ $column-titles[not($$ eq null)] ] })</pre>\n<p>By forking it from github the web scraper may be easily extended with new features.</p>", "tags" : [ "tutorial", "jsoniq" ] }, { "title" : "JSONiq and API Integration Tutorial", "id" : "/81374610314/jsoniq-and-api-integration-tutorial", "updated" : "Tue, 01 Apr 2014 04:06:51 -0400", "summary" : "This is a tutorial for using JSONiq to interface with an external web API to process JSON data.", "content" : "<p>This is a tutorial for using <a href=\"http://www.jsoniq.org/\">JSONiq</a> to interface with an external web API to process JSON data.</p>\n<h2>The Data</h2>\n<p>Suppose you&#8217;re a movie buff who likes all kinds of movies: everything from classic Hitchcock to contemporary comedies. If you live in San Francisco, you can take advantage of the <a href=\"https://data.sfgov.org/\">San Francisco Data</a> site that makes a wide range of city government data available for free. One of the data sets just so happens to be the <a href=\"https://data.sfgov.org/Arts-Culture-and-Recreation-/Film-Locations-in-San-Francisco/yitu-d5am\">Film Locations in San Francisco</a> that includes the title, location, director, lead actors, and fun facts about all films shot on location in San Francisco from 1924 to 2010. The data is downloadable in a number of formats and accessible via their Socrata Open Data (SODA) API in <a href=\"https://data.sfgov.org/resource/yitu-d5am.json\">JSON</a>.</p>\n<h2>Reading the Data</h2>\n<p>Given the data, let&#8217;s write a simple JSONiq program just to read the data for now:</p>\n<pre>    import module namespace http = \"http://zorba.io/modules/http-client\";\n    import module namespace jn = \"http://jsoniq.org/functions\";\n\n    let $movies-uri := \"https://data.sfgov.org/resource/yitu-d5am.json\"\n    let $movies-text := http:get-text( $movies-uri )\n    let $movies-json := jn:parse-json( $movies-text )\n    return $movies-json</pre>\n<p>The above program imports both the <a href=\"http://www.zorba.io/documentation/latest/modules/zorba/io/http-client\">HTTP</a> and <a href=\"http://www.zorba.io/documentation/latest/modules/jsoniq/core\">JSON</a> modules, declares <code>$movies-uri</code> to point to the movie data, reads the data as text into <code>$movies-text</code>, and parses the text as JSON into <code>$movies-json</code>. When run, the program will print all the data in JSON.</p>\n<h2>Viewing the Data</h2>\n<p>The problem is that looking at raw JSON data isn&#8217;t very helpful. What would be better is if there were a way to plot the movies onto a map of San Francisco. It turns out that there&#8217;s a not-too-difficult way to do this by translating the JSON data into <a href=\"http://en.wikipedia.org/wiki/Keyhole_Markup_Language\">KML</a> and then loading that into <a href=\"http://en.wikipedia.org/wiki/Google_Earth\">Google Earth</a>: every movie location will have a push-pin on the map. However, in order to place a pin on the map, we have to know the pin&#8217;s location in latitude &amp; longitude. The locations given in the JSON data are addresses, e.g.:</p>\n<pre>    555 Market St.\n    Mason &amp; California Streets (Nob Hill)</pre>\n<p>To convert addresses to latitude &amp; longitude is called <em>geocoding</em> and, fortunately, Google provides an HTTP-based <a href=\"https://developers.google.com/maps/documentation/geocoding\">geocoding API</a>.</p>\n<h2>Geocoding Locations</h2>\n<p>For our purposes, we can form a geocoding API request as follows:</p>\n<blockquote><code><a href=\"https://maps.googleapis.com/maps/api/geocode/json?key=\">https://maps.googleapis.com/maps/api/geocode/json?key=</a></code><em>your_API_key</em><code>&amp;components=locality:San+Francisco&amp;sensor=false&amp;address=</code><em>location</em></blockquote>\n<p>where <em>your_API_key</em> is your <a href=\"https://developers.google.com/maps/documentation/geocoding/#api_key\">individual API key</a> (follow Google&#8217;s instructions to obtain your own key) and <em>location</em> is a value from one of the JSON data&#8217;s <code>locations</code> keys. One API request will have to be made per location so note the API&#8217;s <a href=\"https://developers.google.com/maps/documentation/geocoding/#Limits\">usage limits</a>.</p>\n\n<p>A small JSONiq program to test the API is:</p>\n<pre>    import module namespace http = \"http://zorba.io/modules/http-client\";\n    import module namespace jn = \"http://jsoniq.org/functions\";\n\n    declare variable $api-key as string := \"your_API_key\";\n\n    declare variable $api-request-fixed as string := fn:concat(\n      \"https://maps.googleapis.com/maps/api/geocode/json\",\n      \"?key=\", $api-key,\n      \"&amp;components=locality:San+Francisco\",\n      \"&amp;sensor=false\",\n      \"&amp;address=\"\n    );\n\n    let $location := \"Mason &amp; California Streets (Nob Hill)\"\n    let $loc-encoded := fn:encode-for-uri( $location )\n    let $api-request-uri := fn:concat( $api-request-fixed, $loc-encoded )\n    let $http-response := http:get-text( $api-request-uri )\n    return\n      if ( $http-response.status eq 200 )\n      then\n        let $api-response-text := $http-response.body.content\n        let $api-response-json := jn:parse-json( $api-response-text )\n        return\n          if ( $api-response-json.status eq \"OK\" )\n          then\n            (: TO-DO :)\n          else\n            () (: API request failed :)\n      else\n        () (: HTTP request failed :)</pre>\n<p>The above program declares <code>$api-request-fixed</code> to be the fixed part of the request: the only part that varies is the location (address) that we append using <code>fn:concat()</code>. Fortunately, Google&#8217;s API is very liberal in the forms of addresses it accepts and it ignores unnecessary information (as is shown above using one of the locations from the movie data). However, it still has to be <em>escaped</em> for inclusion in a URI using <code>fn:encode-for-uri()</code>.</p>\n\n<p>Within the <code>$http-response</code>, we must first check the value of the <code>status</code> sub-key (that contains the <a href=\"http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10\">HTTP status code</a>) to ensure it&#8217;s <a href=\"http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.2.1\">200</a> (which means &#8220;OK&#8221;). After that, we&#8217;re next interested in the value of the <code>body.content</code> sub-key (that contains the actual geocoding API response in JSON) that we parse into <code>$api-response-json</code>. Finally, we check the value of the <code>status</code> sub-key of the API response (which is different from the <code>status</code> of the HTTP response) to ensure it&#8217;s &#8220;OK&#8221; as well.</p>\n\n<p>Within <code>$api-response-json</code>, the additional values of sub-keys that are of interest are: <code>results</code> (a JSON array of all the results), <code>formatted_address</code> (the nicely formatted, geocoded address), <code>lat</code> (the latitude) and <code>lng</code> (the longitude). We can fill-in the <code>TO-DO</code> above as:</p>\n<pre>            let $result-1 := $api-response-json.results[[1]]\n            let $loc-addr := $result-1.formatted_address\n            let $loc-lat := $result-1.geometry.location.lat\n            let $loc-lng := $result-1.geometry.location.lng\n            return\n              {\n                \"address\" : $loc-addr,\n                \"lat\" : $loc-lat,\n                \"lng\" : $loc-lng\n              }</pre>\n<p>We&#8217;ve taken just the first result of the array (using <code>[[1]]</code>) and plucked from it the desired information. When run, the above program will print the nicely formatted address as well as its latitude and longitude as JSON.</p>\n<h2>Generating the KML</h2>\n<p>To generate KML for all movie locations, we can start to combine the programs presented so far as:</p>\n<pre>    let $movies-uri := \"https://data.sfgov.org/resource/yitu-d5am.json\"\n    let $movies-text := http:get-text( $movies-uri )\n    let $movies-json := jn:parse-json( $movies-text )\n    return\n      &lt;kml xmlns=\"http://www.opengis.net/kml/2.2\"&gt;\n        &lt;Document&gt;\n          &lt;name&gt;Movie locations in San Francisco&lt;/name&gt;\n          {\n            for $movie in $movies-json\n            return\n              if ( fn:exists( $movie.locations ) )\n              then\n                (: TO-DO :)\n              else\n                () (: no location :)\n          }\n        &lt;/Document&gt;\n      &lt;/kml&gt;</pre>\n<p>The <code>&lt;kml&gt;</code> and other elements form the structure of the KML. Within the <code>&lt;Document&gt;</code> element, we now iterate through all movies in <code>$movies-json</code>. If you look through the JSON data, you&#8217;ll notice that some locations are missing: we need to check for this using <code>fn:exists()</code> and skip such movie entries. Continuing, we can fill-in the <code>TO-DO</code> above as:</p>\n<pre>                let $loc-encoded := fn:encode-for-uri( $movie.locations )\n                let $api-request-uri := fn:concat( $api-request-fixed, $loc-encoded )\n                let $http-response := http:get-text( $api-request-uri )\n                return\n                  if ( $http-response.status eq 200 )\n                  then\n                    let $api-response-text := $http-response.body.content\n                    let $api-response-json := jn:parse-json( $api-response-text )\n                    return\n                      if ( $api-response-json.status eq \"OK\" )\n                      then\n                        let $result-1 := $api-response-json.results[[1]]\n                        let $loc-addr := $result-1.formatted_address\n                        let $loc-lat := $result-1.geometry.location.lat\n                        let $loc-lng := $result-1.geometry.location.lng\n                        return\n                          (: TO-DO :)\n                      else\n                        () (: API request failed :)\n                  else\n                    () (: HTTP request failed :)</pre>\n<p>This is the same code as before only now using <code>$movie.locations</code>. Finally, the last <code>TO-DO</code> to generate the per-location KML can be filled in as:</p>\n<pre>                          &lt;Placemark&gt;\n                            &lt;name&gt;{$movie.title}&lt;/name&gt;\n                            &lt;description&gt;\n                              {$loc-addr}&lt;![CDATA[&lt;br/&gt;]]&gt;\n                              {$movie.release_year}:\n                              {$movie.actor_1}\n                            &lt;/description&gt;\n                            &lt;Point&gt;\n                              &lt;coordinates&gt;{$loc-lng},{$loc-lat}&lt;/coordinates&gt;\n                            &lt;/Point&gt;\n                          &lt;/Placemark&gt;</pre>\n<p>This gives the name of each pin the name of the movie it represents and each pin&#8217;s description (when the pin is clicked on in Google Earth) the movie&#8217;s exact location, its release year, and its leading actor. The <code>&lt;![CDATA[...]]&gt;</code> section is necessary to enclose arbitrary HTML used to format the description. (Feel free to embelish the HTML as you like.) For the coordinates, note that KML wants it as <em>longitude</em><code>,</code><em>latitude</em>.</p>\n\n<p>When run, the program will print a KML file that can be opened with Google Earth.</p>\n<h2>Closing Remarks</h2>\n<p>We hope that this example has illustrated the relative ease that online data (more of which is becoming available in JSON every day) can be accessed and manipulated using JSONiq. Additionally, JSONiq&#8217;s ability to emit XML natively allows both dominant web data formats, JSON and XML, to be combined seamlessly.</p>", "tags" : [ "tutorial", "jsoniq" ] }, { "title" : "Converting between JSON & CSV", "id" : "/78740141630/converting-between-json--csv", "updated" : "Thu, 06 Mar 2014 06:13:00 -0500", "summary" : "This is a tutorial for the CSV JSONiq module that “… provides an API for parsing and serializing CSV (comma-separated values) files.”", "content" : "<p>This is a tutorial for the <a href=\"http://www.28.io/documentation/latest/modules/data-convertors/json-csv\" target=\"_blank\">CSV</a> JSONiq module that &#8220;&#8230; provides an API for parsing and serializing CSV (comma-separated values) files.&#8221; (See <a href=\"http://tools.ietf.org/html/rfc4180\">RFC 4180, <em>Common Format and MIME Type for Comma-Separated Values (CSV) Files</em>.</a>)</p>\n<h2>The Data</h2>\n<p>Suppose you&#8217;re a foodie who&#8217;s a noodle fanatic. If you could, you&#8217;d eat noodles as part of every meal. You also happen to like food trucks: casual, fast, tasty, and inexpensive. If you live in San Francisco, you can take advantage of the <a href=\"https://data.sfgov.org/\">San Francisco Data</a> site that makes a wide range of city government data available for free. One of the data sets just so happens to be the <a href=\"https://data.sfgov.org/Permitting/Mobile-Food-Schedule/jjew-r69b\">Mobile Food Schedule</a> that includes location, day of week, times, and description of the food sold for every food truck vendor in the city. The data is downloadable in a number of formats including <a href=\"https://data.sfgov.org/api/views/jjew-r69b/rows.csv?accessType=DOWNLOAD\">CSV</a>.</p>\n<h2>Reading the Data</h2>\n<p>Given the data, let&#8217;s write a simple JSONiq program just to read the data for now:</p>\n<pre>    import module namespace csv = \"http://zorba.io/modules/json-csv\";\n    import module namespace http = \"http://zorba.io/modules/http-client\";\n\n    declare variable $truck-csv-uri as xs:string :=\n      \"https://data.sfgov.org/api/views/jjew-r69b/rows.csv?accessType=DOWNLOAD\";\n\n    let $csv := http:get-text( $truck-csv-uri )\n    return csv:parse( $csv )</pre>\n<p>The above program imports both the CSV and HTTP modules, declares <code>$truck-csv-uri</code> to point to the food truck data, reads it into <code>$csv</code>, and parses it using the <code>parse()</code> function of the CSV module. When run, the program will print all the data in JSON.</p>\n<h2>Selecting from the Data</h2>\n<p>Returning to your passion for noodles, we want to select only those food trucks that sell noodles. One way to do this is to write a <code>sells-noodles()</code> function that takes an individual food truck&#8217;s data and returns <code>true</code> or <code>false</code> as to whether the truck sells noodles:</p>\n<pre>    declare function local:sells-noodles( $truck as object )\n      as boolean\n    {\n      contains( lower-case( $truck.optionaltext ), \"noodle\" )\n    };</pre>\n<p>For the Mobile Food Schedule data, the <code>optionaltext</code> field contains the food items sold. We convert it to lower-case so the word &#8220;noodle&#8221; matches regardless of the case of the data. By having the details particular to that data in a separate function, it makes the main program cleaner. Given that function, we can rewrite our main program as:</p>\n<pre>    let $csv := http:get-text( $truck-csv-uri )\n    for $truck in csv:parse( $csv )\n    return\n      if ( local:sells-noodles( $truck ) )\n      then\n        {\n          \"location\" : $truck.Location,\n          \"day\" : $truck.DayOfWeekStr,\n          \"start-time\" : $truck.starttime,\n          \"end-time\" : $truck.endtime,\n          \"description\" : $truck.optionaltext\n        }\n      else\n        ()</pre>\n<p>The data also contains a lot of fields we&#8217;re not interested in; hence we can create our own JSON object to return that contains a subset of the data, in this case the truck&#8217;s location, and the day of the week and times it&#8217;s there. However, when this program is run, we get the error:</p>\n<pre>    &lt;/tmp/food_truck.jq&gt;:10,31: type error [err:XPTY0004]: js:null can not be promoted\n    to parameter type xs:string? of function lower-case()</pre>\n<p>This is because the original CSV data has missing values for some fields for some trucks. The default behavior of the CSV module is to replace missing values with the JSON <code>null</code> value that can&#8217;t be passed to the <code>lower-case()</code> function. Fortunately, the CSV module&#8217;s <code>parse()</code> function can take a set of optional parameters, one of which is what to do for missing values:</p>\n<pre>    let $csv := http:read-text( $truck-csv-uri )\n    let $csv-options := { \"missing-value\" : \"omit\" }\n    for $truck in csv:parse( $csv, $csv-options )\n    return\n      (: ... as before ... :)</pre>\n<p>The <code>missing-value</code> option can take one of three values:</p>\n<blockquote>\n<div><code>\"error\"</code>Error <code>csv:MISSING_VALUE</code> is raised.<code>\"omit\"</code>Both the value and its key are omitted from the result object.<code>\"null\"</code>The value is set to <code>null</code>.</div>\n</blockquote>\n<p>The <code>\"null\"</code> value is the default when no options are specified, but we have specified the <code>\"omit\"</code> value above. When the program is re-run, it runs to completion without error printing only those food trucks that sell noodles.</p>\n<h2>Serializing the Data</h2>\n<p>If we want to print the data back as CSV rather than JSON, say for importing into a spreadsheet, the CSV module also allows for serializing the data as CSV. To do this, we introduce another variable <code>$noodle-trucks</code> that holds the previous result of just the trucks that sell noodles in order to pass them to the <code>csv:serialize()</code> function:</p>\n<pre>    let $csv := file:read-text( $csv-file )\n    let $csv-options := { \"missing-value\" : \"omit\" }\n    let $noodle-trucks :=\n      for $truck in csv:parse( $csv, $csv-options )\n      return\n        (: ... as before ... :)\n    return csv:serialize( $noodle-trucks )</pre>\n<h2>Closing Remarks</h2>\n<p>The CSV module has many more options, both for parsing and serializing CSV data; see the <a href=\"http://www.28.io/documentation/latest/modules/data-convertors/json-csv\" target=\"_blank\">documentation</a> for details.</p>\n<p>Author: Paul Lucas - <a href=\"mailto:paul@28.io\">paul@28.io</a></p>", "tags" : [ "tutorial", "jsoniq" ] }, { "title" : "Win Free NoSQL eXchange Ticket!", "id" : "/67680794793/win-free-nosql-exchange-ticket", "updated" : "Thu, 21 Nov 2013 15:02:00 -0500", "summary" : null, "content" : "<p><img alt=\"image\" class=\"pull-left add-right-margin\" src=\"http://media.tumblr.com/b2eb9e1c9e4b334b2a995ee99764422c/tumblr_inline_mwmqj2km361rjv2qx.png\"/></p>\n<p>On November 28th 2013, <a href=\"http://skillsmatter.com\" target=\"_blank\">Skills Matter London</a> is organizing the third annual <a href=\"http://skillsmatter.com/event/nosql/nosql-exchange\" target=\"_blank\">NoSQL eXchange</a>.</p>\n<p>We are giving away a free ticket to the event. Be fast and <a href=\"mailto:hello@28.io\">email us</a> first to get your free ticket. A special 25% discount off the price of a NoSQL eXchange ticket is also available. Simply enter SM2652-NOSQLX-25 into the conference booking system <a href=\"https://skillsmatter.com/register-online/conf/1567\" target=\"_blank\">right here</a>.</p>\n<p>If you are participating to the event, make sure to grab your free copy of the <a href=\"http://www.28.io/jsoniq-the-sql-of-nosql\">JSONiq book</a>. See you in London!</p>\n<div class=\"clearfix\"></div>", "tags" : [ "events" ] }, { "title" : "Meet us at Strata London 2013", "id" : "/65022047192/meet-us-at-strata-london-2013", "updated" : "Fri, 25 Oct 2013 00:55:00 -0400", "summary" : "28msec is proud to be a Premier Exhibitor at the Strata Conference in London, England, November 11 - 13, 2013. If the conference organizers are asking you to become an active driver of your data, then let us show you the steering wheel and the accelerator that you will need to race into the future.", "content" : "<p><img alt=\"image\" class=\"pull-left add-right-margin\" src=\"http://media.tumblr.com/6a1b5617d3bac1d6c4740e554ac3f98c/tumblr_inline_mv7ff2mQKz1spfjs1.jpg\"/></p>\n<p>28msec is proud to be a Premier Exhibitor at the <a href=\"http://strataconf.com/strataeu2013\" target=\"_blank\">Strata Conference in London, England, November 11 - 13, 2013</a>. If the conference organizers are asking you to become an active driver of your data, then let us show you the steering wheel and the accelerator that you will need to race into the future.</p>\n<p>If you are collecting big data, chances are you are also experiencing the big complexity and big cost that comes with it. We have been working hard to put big data on a diet, making it more accessible and informative.</p>\n<p>Nowadays, organizations typically use a variety of data storage technologies for different kinds of data, from relational databases, to document stores, to cloud services. 28.io is a unified information access platform that breaks down these data silos and empowers its users to easily extract actionable information from across all of their data stores.</p>\n<p>Stop by our stand (#206) to get inspired by seeing some of our use cases, and to delve into our technology as deep as you&#8217;d like!</p>", "tags" : [ "events" ] }, { "title" : "White paper: eDiscovery - To Search Or To Query", "id" : "/65020666933/white-paper-ediscovery--to-search-or-to-query", "updated" : "Fri, 25 Oct 2013 00:33:00 -0400", "summary" : "The challenge of eDiscovery lies in the processing of a variety of data formats from different data sources under high time pressure. In this white paper, we describe how 28.io and JSONiq provide a solution to seamlessly combine search and query, so that analyst time is spent where is matters most: in the interpretation of the results.", "content" : "<p>Read our <a href=\"http://info.28.io/772AKE21000000X004e4E00\" target=\"_blank\">eDiscovery white paper</a> to find out how to query metadata and join it with full-text search results in a mere ten lines of JSONiq.</p>\n<p>Because eDiscovery actually does not have the luxury of this choice. Most of the time, the data that is relevant for eDiscovery was never meant to be analyzed. While some of it may be structured information from enterprise applications, more and more data will come from unstructured sources such as email or chat communication. How can you obtain a complete picture of all this information when there is no time for transforming the entirety into a single common structure?</p>\n<p>28.io offers a unified information access platform in the cloud, which can process data in any format from any source at high speed. At the heart of it is JSONiq, a powerful query language for data of any kind of structure, and which is automatically parallelized for efficient execution. The platform&#8217;s strength lies in its ability to access and join disparate data sources and allows for arbitrary data structures to be discovered during analysis.</p>", "tags" : [ "white-paper", "use-case" ] }, { "title" : "Join us at Strata NY 2013", "id" : "/64777937839/join-us-at-strata-ny-2013", "updated" : "Tue, 22 Oct 2013 11:28:00 -0400", "summary" : "28.io will be exhibiting at the Strata Conference in New York, NY, October 28 - 30, 2013. This is an excellent venue to showcase our technology because we share the passion of the conference: \"Making Data Work.\"", "content" : "<p><img alt=\"image\" class=\"pull-left add-right-margin\" src=\"//cdn.oreillystatic.com/en/assets/1/eventseries/23/strata_franchise_ny_hadoop_tm.jpg\"/></p>\n<p>28.io will be exhibiting at the <a href=\"http://strataconf.com/stratany2013?intcmp=il-strata-stny13-franchise-page\">Strata Conference in New York, NY, October 28 - 30, 2013</a>. This is an excellent venue to showcase our technology because we share the passion of the conference: &#8220;Making Data Work.&#8221;</p>\n<p>If you are collecting big data, chances are you are also experiencing the big complexity and big cost that comes with it. We have been working hard to put big data on a diet, making it more accessible and informative.</p>\n<p>Nowadays, organizations typically use a variety of data storage technologies for different kinds of data, from relational databases, to document stores, to cloud services. At 28.io, we are a unified information access platform that breaks down these data silos and empowers its users to easily extract actionable information from across all of their data stores.</p>\n<p>Stop by our booth (#12) to get inspired by seeing some of our use cases, and to delve into our technology as deep as you&#8217;d like!</p>\n<div class=\"clearfix\"></div>", "tags" : [ "events" ] }, { "title" : "A Big Data Solution using JSONiq", "id" : "/58423239104/a-big-data-solution-using-jsoniq", "updated" : "Fri, 16 Aug 2013 10:54:00 -0400", "summary" : "On August 26h during the next ACM event in silicon valley, 28.io CTO Matthias Brantner will present a \"A Big Data Solution using JSONiq.\" \n  If you are in the area, be sure to check it out.", "content" : "<p><span>On August 26h during the next ACM event in silicon valley, 28.io CTO Matthias Brantner will present a </span><a href=\"http://www.meetup.com/SF-Bay-ACM/events/132688732/\">\"A Big Data Solution using JSONiq.\"</a><span> </span></p>\n<p><!-- more --></p>\n<p>If you are in the area, be sure to check it out.</p>\n<p>Big Data and Data Mining are rising in usage and popularity. However, the tools to access, transform, and process semi-structured data are running behind. We will present a case study where we used JSONiq has a high-level declarative query language to process semi-structured data. We were able to turn 1TB of USPTO data into information that can be used by attorneys performing trademark searches. We will also present other applications that involve complex data processing such as financial and healthcare data.</p>\n<p>See you there!</p>", "tags" : [ "jsoniq", "events" ] }, { "title" : "Polyglot Queries with JSONiq", "id" : "/56455801961/polyglot-queries-with-jsoniq", "updated" : "Thu, 25 Jul 2013 17:25:00 -0400", "summary" : "Nowadays organizations have a variety of different data storage technologies for different kinds of data. From relational databases to document stores and cloud services. And because each technology has its own data model and interface to be learned, it can be extremely challenging to process these different sources into valuable information.", "content" : "<p>Nowadays organizations have a variety of different data storage technologies for different kinds of data. From relational databases to document stores and cloud services. And because each technology has its own data model and interface to be learned, it can be extremely challenging to process these different sources into valuable information.</p>\n<p><!-- more --></p>\n<p>We think that <a href=\"http://jsoniq.org\" target=\"_blank\">JSONiq</a> can help with that. Below is a short screencast to showcase how you can use JSONiq to write a query across three different datasources: MySQL, MongoDB, and ZenDesk. We hope that you will enjoy it.</p>\n<div class=\"wistia_embed\" id=\"wistia_ovvc4kh9du\">\n<div><object classid=\"denied:clsid:D27CDB6E-AE6D-11cf-96B8-444553540000\" id=\"wistia_ovvc4kh9du_seo\"><param name=\"movie\" value=\"http://embed.wistia.com/flash/embed_player_v2.0.swf?2013-07-03\"><param name=\"allowfullscreen\" value=\"true\"><param name=\"allowscriptaccess\" value=\"always\"><param name=\"bgcolor\" value=\"#000000\"><param name=\"wmode\" value=\"opaque\"><param name=\"flashvars\" value=\"autoPlay=false&amp;banner=false&amp;controlsVisibleOnLoad=true&amp;customColor=7b796a&amp;endVideoBehavior=default&amp;fullscreenDisabled=true&amp;mediaDuration=357.0&amp;playButtonVisible=true&amp;showPlayButton=true&amp;showPlaybar=true&amp;showVolume=true&amp;stillUrl=http%3A%2F%2Fembed.wistia.com%2Fdeliveries%2F31b4f17f5955009c152d7509beba69cc2202c3d9.jpg%3Fimage_crop_resized%3D640x480&amp;unbufferedSeek=false&amp;videoUrl=http%3A%2F%2Fembed.wistia.com%2Fdeliveries%2Ff1235a5df856c038e90b2011d4c59749f2889271.bin\"></object></div>\n</div>\n<p>\n<script charset=\"ISO-8859-1\" src=\"http://fast.wistia.com/static/concat/E-v1.js\" type=\"text/javascript\"></script><script type=\"text/javascript\">// <![CDATA[\nwistiaEmbed = Wistia.embed(\"ovvc4kh9du\");\nwistiaEmbed.bind(\"play\", function(){\n    mktoMunchkinFunction ('visitWebPage',{ url: document.location.path, params: 'playedVideo=25' }, Sha1.hash('81f35d90c6b011e28b8b0800200c9a66' + window.wemail));\n});\nwistiaEmbed.bind(\"timechange\", function(second){\n    var total = wistiaEmbed.duration();\n    if(Math.floor(second) === Math.floor(total/2)) {\n        mktoMunchkinFunction ('visitWebPage',{ url: document.location.path, params: 'playedVideo=50' }, Sha1.hash('81f35d90c6b011e28b8b0800200c9a66' + window.wemail));\n    }\n});\nwistiaEmbed.bind(\"end\", function(){\n    mktoMunchkinFunction ('visitWebPage',{ url: document.location.path, params: 'playedVideo=100' }, Sha1.hash('81f35d90c6b011e28b8b0800200c9a66' + window.wemail));\n});\n// ]]></script><script charset=\"ISO-8859-1\" src=\"http://fast.wistia.com/embed/medias/ovvc4kh9du/metadata.js\" type=\"text/javascript\"></script></p>\n<p>If you are looking to hack some JSONiq queries, <a href=\"http://28.io/demo\">our live demo</a> is a good place to start. Ghislain Fourny recently published an awesome book about JSONiq, <a href=\"http://www.28.io/jsoniq-the-sql-of-nosql\">the ebook version is available for free</a>.</p>\n<p>Stay tuned for more!</p>", "tags" : [ "jsoniq", "tutorial" ] }, { "title" : " Webinar: Innovations in NoSQL Query Languages", "id" : "/56226766999/-webinar-innovations-in-nosql-query-languages", "updated" : "Tue, 23 Jul 2013 04:43:00 -0400", "summary" : "Today, 28.io CTO Matthias Brantner will be interviewed about JSONiq and modern query processing techniques for today’s data challenges. Be sure to subscribe to the webinar.", "content" : "<p>Today, 28.io CTO Matthias Brantner will be interviewed about JSONiq and modern query processing techniques for today&#8217;s data challenges. Be sure to subscribe to the webinar <a href=\"http://www.dataversity.net/nosql-now-jul-23-webinar-innovations-in-nosql-query-languages/\" target=\"_blank\">here</a>.<!-- more --></p>\n<p class=\"pagination-centered\"><a href=\"http://www.dataversity.net/nosql-now-jul-23-webinar-innovations-in-nosql-query-languages/\" target=\"_blank\"> <img alt=\"NoSQL Now Webinar Series\" height=\"189\" src=\"http://www.dataversity.net/wp-content/uploads/2013/06/NoSQL-Now-Webinar-Series-300x189.png\" width=\"300\"/></a></p>\n<p><strong>Update</strong><br/> The recording of the webinar is available below.</p>\n<p><iframe frameborder=\"0\" height=\"356\" marginheight=\"0\" marginwidth=\"0\" scrolling=\"no\" src=\"http://www.slideshare.net/slideshow/embed_code/24633683?rel=0\" width=\"427\"></iframe></p>", "tags" : [ "webinar", "jsoniq" ] }, { "title" : "JSONiq @ MongoDB Meetup Munich", "id" : "/55287031023/jsoniq--mongodb-meetup-munich", "updated" : "Fri, 12 Jul 2013 17:29:00 -0400", "summary" : "If you are in the Bavaria region next week, make sure to attend the JSONiq introduction from Alexander Kreutz at the Munich MongoDB meetup. Alexander will give a high-level overview about JSONiq and about the importance of declarative query languages in the NoSQL space.", "content" : "<p>If you are in the Bavaria region next week, make sure to attend the JSONiq introduction from <a href=\"/company/team\">Alexander Kreutz</a> at the <a href=\"http://www.meetup.com/Muenchen-MongoDB-User-Group/events/126589072/\">Munich MongoDB meetup</a>. Alexander will give a high-level overview about JSONiq and about the importance of declarative query languages in the NoSQL space. He will then showcase a couple of JSONiq query examples running on top of MongoDB.<!-- more --></p>\n<p>The meetup will be on July 17th at comSysto GmbH. More information is available <a href=\"http://www.meetup.com/Muenchen-MongoDB-User-Group/events/126589072/\">here</a>.</p>\n<p><strong>Update</strong></p>\n<p>For german speaking developers, the video of the talk is available on <a href=\"http://www.youtube.com/watch?v=PIAJi3rt-RE\" target=\"_blank\">youtube.</a></p>\n<p><iframe frameborder=\"0\" height=\"315\" src=\"//www.youtube.com/embed/PIAJi3rt-RE\" width=\"560\"></iframe></p>", "tags" : [ "events" ] }, { "title" : "28msec @ GigaOM Structure 2013 LaunchPad", "id" : "/54710364207/28msec--gigaom-structure-2013-launchpad", "updated" : "Fri, 05 Jul 2013 20:10:00 -0400", "summary" : "Last month, Matthias Brantner presented the company at GigaOM Structure 2013 LaunchPad. You can checkout the presentation below.", "content" : "<p>Last month, Matthias Brantner presented the company at <a href=\"http://event.gigaom.com/structure/launchpad/\" target=\"_blank\">GigaOM Structure 2013 LaunchPad</a>. You can checkout the presentation below.<!-- more --></p>\n<p><iframe frameborder=\"0\" height=\"315\" src=\"//www.youtube.com/embed/4Vv-r2r5-eE\" width=\"560\"></iframe></p>", "tags" : [  ] }, { "title" : "Query Languages for Document Stores", "id" : "/52705750475/query-languages-for-document-stores", "updated" : "Tue, 11 Jun 2013 09:22:00 -0400", "summary" : "Last April, at NoSQL Matters Cologne, Jan Steemann from triAGENS gave an excellent overview of query languages for document stores. We hope that you will enjoy the video of his presentation", "content" : "<p>Last April, at <a href=\"http://2013.nosql-matters.org/cgn/abstracts/\">NoSQL Matters Cologne</a>, Jan Steemann from triAGENS gave an excellent overview of query languages for document stores. We hope that you will enjoy the video of his presentation<!-- more --></p>\n<p><iframe frameborder=\"0\" height=\"281\" src=\"http://player.vimeo.com/video/66159278\" width=\"500\"></iframe></p>\n<p><a href=\"http://vimeo.com/66159278\">NoSQL matters Cologne 2013 Day1 Track2&#160;04 Jan Steemann</a> from <a href=\"http://vimeo.com/user9636686\">NoSQL matters</a> on <a href=\"http://vimeo.com\">Vimeo</a>.</p>", "tags" : [ "events", "jsoniq" ] }, { "title" : "JSONiq on Tour", "id" : "/52627762863/jsoniq-on-tour", "updated" : "Mon, 10 Jun 2013 10:32:00 -0400", "summary" : "On June 20th, 28.io CTO Matthias Brantner will battle it out with five other startups at the GigaOM Structure LaunchPad. Matthias will present our commitment to transform information processing into a commodity. In the same way NoSQL document stores are transforming the database landscape, we believe that JSONiq, the SQL of NoSQL, will significantly lower the amount of work and resources required to transform flexible data into actionable information.", "content" : "<p>The conference season is on. This summer, we will participate in several <a href=\"http://www.28.io/events/?filter=mug\">MongoDB User Groups</a> and <a href=\"http://www.28.io/events/?filter=conferences\">conferences</a>.</p>\n<p><!-- more --></p>\n<p>On June 20th, 28.io CTO Matthias Brantner will battle it out with five other startups at the <a href=\"http://event.gigaom.com/structure/launchpad/\">GigaOM Structure LaunchPad</a>. Matthias will present our commitment to transform information processing into a commodity. In the same way NoSQL document stores are transforming the database landscape, we believe that JSONiq, the SQL of NoSQL, will significantly lower the amount of work and resources required to transform flexible data into actionable information.</p>\n<p>Make sure to catch us <a href=\"http://www.28.io/events\">on the road</a>. In the meantime, here are some videos from previous events.</p>\n<p><strong>Do More with MongoDB &amp; JSONiq</strong> - Matthias Brantner</p>\n<p><iframe frameborder=\"0\" height=\"315\" src=\"http://www.youtube.com/embed/7QIPeJeSdhY\" width=\"560\"></iframe></p>\n<p><strong>JSONiq - The SQL of NoSQL</strong> - William Candillon</p>\n<p><iframe frameborder=\"0\" height=\"281\" src=\"http://player.vimeo.com/video/66159277\" width=\"500\"></iframe></p>\n<p><a href=\"http://vimeo.com/66159277\">NoSQL matters Cologne 2013 Day1 Track2&#160;03 William Candillon</a> from <a href=\"http://vimeo.com/user9636686\">NoSQL matters</a> on <a href=\"http://vimeo.com\">Vimeo</a>.</p>", "tags" : [ "events", "jsoniq" ] }, { "title" : "Webinar: JSONiq - The SQL of NoSQL", "id" : "/52380807156/webinar-jsoniq--the-sql-of-nosql", "updated" : "Fri, 07 Jun 2013 10:37:00 -0400", "summary" : "The NoSQL movement is breaking free from the flat and rigid relational data model. By doing so, developers are losing the industry standard query language: SQL. SQL doesn’t provide any semantics for navigating, constructing, or comparing hierarchical data. The lack of high level query languages in the SQL space put a tremendous amount of pressure on NoSQL developers.", "content" : "<p>The NoSQL movement is breaking free from the flat and rigid relational data model. By doing so, developers are losing the industry standard query language: SQL. SQL doesn&#8217;t provide any semantics for navigating, constructing, or comparing hierarchical data. The lack of high level query languages in the SQL space put a tremendous amount of pressure on NoSQL developers.<!-- more --></p>\n<div class=\"wistia_embed\" id=\"wistia_xovsdld6c6\">\n<div><object classid=\"denied:clsid:D27CDB6E-AE6D-11cf-96B8-444553540000\" id=\"wistia_xovsdld6c6_seo\"><param name=\"movie\" value=\"http://embed.wistia.com/flash/embed_player_v2.0.swf?2013-07-03\"><param name=\"allowfullscreen\" value=\"true\"><param name=\"allowscriptaccess\" value=\"always\"><param name=\"bgcolor\" value=\"#000000\"><param name=\"wmode\" value=\"opaque\"><param name=\"flashvars\" value=\"controlsVisibleOnLoad=true&amp;endVideoBehavior=reset&amp;mediaDuration=2250.0&amp;showVolume=true&amp;stillUrl=http%3A%2F%2Fembed.wistia.com%2Fdeliveries%2F2364e65d2758b4774c701697947cb01fb260a18e.jpg%3Fimage_crop_resized%3D640x480&amp;unbufferedSeek=true&amp;videoUrl=http%3A%2F%2Fembed.wistia.com%2Fdeliveries%2F717e958e09bc14b46a979ac9b98f08dd20fe3a70.bin\"></object></div>\n</div>\n<p>JSONiq is a high-level query language that enables NoSQL developers to develop and execute complex queries productively on top of their data stores of choice. JSONiq targets three aspects of the NoSQL query languages: standardization, complex processing, and functions &amp; operators. In this webinar, we gave an overview about the JSONiq query language and about why high-level query languages are extremely important in the NoSQL space. We then dived into specific JSONiq examples where we highlighted the various language capabilities that are in action.</p>", "tags" : [ "jsoniq", "tutorial", "webinar" ] }, { "title" : "Windowing Queries on top of MongoDB", "id" : "/51483608622/windowing-queries-on-top-of-mongodb", "updated" : "Mon, 27 May 2013 12:53:00 -0400", "summary" : "Windowing queries are extremely useful to perform analysis on sequential data. We have set up a short screencast that showcases an example of a windowing query on top of a MongoDB deployment. We hope that you will check it out.", "content" : "<p>Windowing queries are extremely useful to perform analysis on sequential data. We have set up a short screencast that showcases an example of a windowing query on top of a MongoDB deployment. We hope that you will check it out.</p>\n<p><!-- more --></p>\n<div class=\"wistia_embed\" id=\"wistia_ti0odglinh\">\n<div><object classid=\"denied:clsid:D27CDB6E-AE6D-11cf-96B8-444553540000\" id=\"wistia_ti0odglinh_seo\"><param name=\"movie\" value=\"http://embed.wistia.com/flash/embed_player_v2.0.swf?2013-07-03\"><param name=\"allowfullscreen\" value=\"true\"><param name=\"allowscriptaccess\" value=\"always\"><param name=\"bgcolor\" value=\"#000000\"><param name=\"wmode\" value=\"opaque\"><param name=\"flashvars\" value=\"controlsVisibleOnLoad=true&amp;endVideoBehavior=reset&amp;mediaDuration=374.0&amp;showVolume=true&amp;stillUrl=http%3A%2F%2Fembed.wistia.com%2Fdeliveries%2F4cc0194a02f4f8819ff61dbba82ec6765257397f.jpg%3Fimage_crop_resized%3D640x480&amp;unbufferedSeek=false&amp;videoUrl=http%3A%2F%2Fembed.wistia.com%2Fdeliveries%2Fb92b207dbebbb9921859d14f970823b74e193bab.bin\"></object></div>\n</div>\n<p><a href=\"http://jsoniq.org\">JSONiq</a> provides two types of windowing expressions: sliding and tumbling windows. Sliding windows are windows that may overlap; tumbling windows donât. These two types of windowing expressions can be seen in the picture below. <img alt=\"image\" src=\"http://www.28.io/img/blog/windowing.png\"/></p>\n<p>The demo shown in the screencast is as follows: Our MongoDB contains a collection of answers from <a href=\"http://stackoverflow.com\">stackoverflow</a>. We would like to use JSONiq to answer the following question: <em>how many days in a row, has a contributor at least answered one question per day?</em></p>\n<p>We start by grouping and sorting the answers by contributor and creation date.</p>\n<pre class=\"ace-static\">for $answers in collection(âanswersâ)\ngroup by $user-id := $answers.owner.user_id\nlet $answers := for $answer in $answers\n                order by $answer.creation_date\n                return $answers\n</pre>\n<p>For each group, we would like to compute the different contribution streaks. This is where the windowing expression comes in. We want to start the window whenever possible. We close the contribution window when the next answer&#8217;s creation date is more than one day apart from the previous one. These conditions are expressed in the following query:</p>\n<pre class=\"ace-static\">let $streaks := for tumbling window $answers in $answers\n                start $start when true\n                end $end next $next when\n                    $next.creation_date - $end.creation_date\n                    gt dayTimeDuration(\"P1D\")\n                return $end.creation_date - $start.creation_date\n</pre>\n<p>Finally, we select the maximum contribution window, order the groups from the user contribution streaks, and return the username and largest contribution streak. This is what the final query looks like:</p>\n<pre class=\"ace-static\">for $answers in collection(\"answers\")\ngroup by $user-id := $answers.owner.user_id\n\nlet $answers := for $answer in $answers\n                order by $answer.creation_date\n                return $answer\n               \nlet $streaks := for tumbling window $answers in $answers\n                start $start when true\n                end $end next $next when\n                  $next.creation_date - $end.creation_date\n                  gt dayTimeDuration(\"P1D\")\n                return $end.creation_date - $start.creation_date\n\nlet $streak := max($streaks)\n\norder by $streak descending\nreturn {\n  \"username\": $answers[1].owner.display_name,\n  \"largest contribution streak\": days-from-duration($streak)\n}</pre>\n<p>There are a couple of nice things about this query. First, you&#8217;ll notice that expressions can be nested. This is one of the key benefit of JSONiq: all expressions are fully composable. Second, this query leverages fairly advanced functions and operators. It subtracts dates to get a duration, the duration is compared to another and finally gets converted into a number of days. These types of operations are seamless to do with JSONiq. Last but not least, windowing expressions work in a completely streamable manner. This is extremely convenient for large sequences of data.</p>\n<p>We hope that you will find creative ways to use windowing queries for your data and we are looking forward to hearing from you.</p>", "tags" : [ "jsoniq", "mongodb", "tutorial" ] }, { "title" : "JSONiq Queries on top of MongoDB", "id" : "/50508198602/jsoniq-queries-on-top-of-mongodb", "updated" : "Wed, 15 May 2013 14:11:00 -0400", "summary" : "When it comes to turn your MongoDB data into actionable information, JSONiq takes your productivity to a new level. And it’s easy to get started with. On top of the demo queries that are available, we produced a short screencast that showcases simple yet powerful queries written with JSONiq. We hope that you will enjoy it.", "content" : "<p>When it comes to turn your MongoDB data into actionable information, <a href=\"http://jsoniq.org\">JSONiq</a> takes your productivity to a new level. And it&#8217;s easy to get started with. On top of <a href=\"http://portal.28.io/trynow/start\">the demo queries that are available</a>, we produced a short screencast that showcases simple yet powerful queries written with JSONiq. We hope that you will enjoy it.</p>\n<p><!-- more --></p>\n<div class=\"wistia_embed\" id=\"wistia_jun83pd1hb\">\n<div><object classid=\"denied:clsid:D27CDB6E-AE6D-11cf-96B8-444553540000\" id=\"wistia_jun83pd1hb_seo\"><param name=\"movie\" value=\"http://embed.wistia.com/flash/embed_player_v2.0.swf?2013-07-03\"><param name=\"allowfullscreen\" value=\"true\"><param name=\"allowscriptaccess\" value=\"always\"><param name=\"bgcolor\" value=\"#000000\"><param name=\"wmode\" value=\"opaque\"><param name=\"flashvars\" value=\"controlsVisibleOnLoad=true&amp;endVideoBehavior=reset&amp;mediaDuration=467.0&amp;showVolume=true&amp;stillUrl=http%3A%2F%2Fembed.wistia.com%2Fdeliveries%2Fdc82945fc2101b11fd69ab6ee2faa579ac0b69ab.jpg%3Fimage_crop_resized%3D640x480&amp;unbufferedSeek=true&amp;videoUrl=http%3A%2F%2Fembed.wistia.com%2Fdeliveries%2F945a161ac03ad49392babed798584dce9ebe7e46.bin\"></object></div>\n</div>\n<p>We broke down the demo in two parts.</p>\n<h3>Bring Your Own MongoDB</h3>\n<p>When creating a project on 28.io, you can connect to your MongoDB deployment of choice. 28.io will automatically extract the metadata from your collections and indexes allowing you to execute queries on your data. We answer frequently asked questions for developers looking to connect to their own MongoDB deployment in our <a href=\"https://28msec.zendesk.com/forums/22040792-Bring-Your-Own-MongoDB-Database\">support section</a>.</p>\n<h3><em>FLWOR</em> Power</h3>\n<p>Every JSONiq construct is an expression, and expressions are fully composable. The main expression in the JSONiq language is called the <em>FLWOR</em>, an acronym for <code>for</code>, <code>let</code>, <code>where</code>, <code>order by</code> and <code>return</code>. FLWOR expressions support projections, selections, joins, outer joins, and have been recently extended with group-by, count, and windowing clauses. For instance, in the code snippet below, we select all answered questions from the <a href=\"http://stackoverflow.com\">stackoverflow</a> dataset and order the result by creation date. Finally, we format the creation date in French.</p>\n<pre class=\"ace-static\">for $question in collection(\"faq\")\nwhere $question.is_answered\norder by $question.creation_date descending\nreturn {\n    \"title\": $question.title,\n    \"creation_date\": format-dateTime($question.creation_date, \"[D] [MNn] [Y]\", \"fr_FR\", (), ())\n}</pre>\n<p>The following code snippet showcases the group-by clause. For each stackoverflow answer, we group the answers by contributor, count the number of answers for each group, and return the list of contributors ordered by the number of questions answered.</p>\n<pre class=\"ace-static\">for $answers in collection(\"answers\")\ngroup by $user-id := $answers.owner.user_id\nlet $count := count($answers)\norder by $count descending\nreturn {\n    \"username\": $answers[1].owner.display_name,\n    \"number of answers\": $count\n}</pre>\n<p>JSONiq is also convenient for running joins efficiently. Our demo project contains two collections: questions and answers. Each answer contains a reference to its corresponding question. The problem with such set-up is that MongoDB doesn&#8217;t provide a way to join documents across collections. If we were to write our application without JSONiq, we would write a first query to pull out the answers and then for each group write another query to pull out the question titles. We would end up doing multiple queries in our application and doing the joins more or less manually in our code. With JSONiq, we can easily join two collections. For instance, in the code snippet below, we display the question titles that each user has answered.</p>\n<pre class=\"ace-static\">for $answers in collection(\"answers\")\ngroup by $user-id := $answers.owner.user_id\nlet $count := count($answers)\norder by $count descending\nreturn {\n    \"username\": $answers[1].owner.display_name,\n    \"number of answers\": $count,\n    \"titles\": collection(\"faq\")[\n        some $question-id in $answers.question_id\n          satisfies $question-id eq $$.question_id\n    ].title\n}</pre>\n<p>We hope that JSONiq will help you to write complex queries on top of MongoDB and that you will stay tuned for more.</p>", "tags" : [ "jsoniq", "mongodb", "tutorial" ] }, { "title" : "Query Platform for MongoDB", "id" : "/48613691865/query-platform-for-mongodb", "updated" : "Mon, 22 Apr 2013 10:43:00 -0400", "summary" : "We are very pleased to announce the first release of 28.io, our query platform for MongoDB. At 28msec, we believe that a productive query language can transform a scalable document store into a full-fledged database management system. Our goal is to remove the burden of implementing and optimizing complex query processing from MongoDB users so they can focus on building features for their business.", "content" : "<p>We are very pleased to announce the first release of <a href=\"/\">28.io</a>, our query platform for <a href=\"http://mongodb.org\">MongoDB</a>.</p>\n<p><!-- more --></p>\n<p>At 28msec, we believe that a productive query language can transform a scalable document store into a full-fledged database management system. Our goal is to remove the burden of implementing and optimizing complex query processing from MongoDB users so they can focus on building features for their business. We bring powerful query capabilities to MongoDB using <a href=\"http://jsoniq.org\">JSONiq</a>. JSONiq supports complex SQL-like features such as joins, grouping, sorting, transformation, full-text search, indexes, and declarative updates. These are database features that developers take for granted in the relational world that are now available to MongoDB. But this is not your grandma&#8217;s SQL. JSONiq takes into consideration the complexities of querying deeply nested, flexible, heterogeneous data.</p>\n<p>If you are looking to see how 28.io can help you to get more from your own MongoDB deployment, this is a three-step process: Bring Your Own MongoDB, Write Complex Queries, and Scale Out.</p>\n<h3>Bring Your Own MongoDB</h3>\n<p>After <a href=\"http://portal.28.io/account/show-register\">creating an account</a>, you can set up a new project that connects directly with your own MongoDB deployment. 28.io will extract the metadata (collections and indexes) from MongoDB automatically and allow you to start querying using JSONiq. For best performance, your MongoDB database should be located in the eastern US (Northern Virginia) Region. Please <a href=\"mailto:hello@28.io\">contact us</a> if you would like to have hosting in a different region.</p>\n<h3>Write Complex Queries</h3>\n<p>JSONiq is a powerful query language designed for flexible data. Using JSONiq will grant productive query capabilities to MongoDB users that are otherwise currently denied to them. In addition, we provide <a href=\"/documentation\">module libraries</a> to enable you to efficiently process strings, numbers, dates, times, timezones, and durations. Demo queries from 28.io are <a href=\"http://portal.28.io/trynow/start\">available</a>.</p>\n<h3>Scale Out</h3>\n<p>Your query workload will be automatically balanced on existing servers, either in a shared mode, or on your dedicated servers. For large datasets or particularly complex queries, a single query execution can be parallelized on several servers.</p>\n<h3>Stay in Touch</h3>\n<p>We are working hard on the platform and to bring you more insights on how it can transform your MongoDB deployment into a full-fledged database. Last week, William Candillon introduced JSONiq at <a href=\"https://speakerdeck.com/wcandillon/jsoniq-the-sql-of-nosql\">NoSQLMatters 2013</a>, in Cologne. If you are in the Los Angeles area, make sure to catch up with Matthias Brantner during the next <a href=\"http://www.meetup.com/Los-Angeles-MongoDB-User-Group/\">Los Angeles MongoDB user group meeting</a>. He will talk about <a href=\"http://www.meetup.com/Los-Angeles-MongoDB-User-Group/events/111354372/\">Doing More with MongoDB and JSONiq</a>. We are also proud finalists of the <a href=\"http://gigaom.com/2013/04/25/meet-our-six-structure-2013.finalists/\">2013 Structure Launchpad from GigaOM</a>. Except to see more from us in the upcoming weeks. In the meantime, may the query be with you!</p>", "tags" : [ "jsoniq", "mongodb", "events" ] } ] }